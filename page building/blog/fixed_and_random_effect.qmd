---
title: "Understanding Fixed Effects vs. Random Effects in Panel Data Analysis"
author: "Heeyoung Lee"
date: "May 15, 2025"
format: 
  html:
    theme: cosmo
    css: custom.css
    code-fold: true
    code-tools: true
    toc: true
    toc-location: left
    self-contained: true
    fig-width: 8
    fig-height: 6
    fig-dpi: 300
    smooth-scroll: true
    highlight-style: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE,
  cache = TRUE,
  fig.align = "center"
)

# Load required packages
library(tidyverse)
library(plm)
library(lme4)
library(kableExtra)
library(patchwork)
library(DT)
```

## Introduction {.animate__animated .animate__fadeIn}

Panel data analysis is a powerful statistical methodology that handles data collected over multiple time periods for the same entities (individuals, firms, counties, etc.). Two of the most common approaches to analyzing panel data are **fixed effects** and **random effects** models.

Panel data combines the features of:
- **Cross-sectional data**: Data from multiple entities at a single point in time
- **Time-series data**: Data from a single entity over multiple time periods

Panel data allows us to control for unobserved heterogeneity, which refers to individual-specific characteristics that are not captured by the observed variables.

In this blog post, I'll demonstrate:

1. What fixed effects and random effects models are
2. How they differ conceptually and mathematically
3. When to use each approach
4. How to implement and interpret them in R

Let's explore these concepts with visualizations and examples!

## The Panel Data Structure {.animate__animated .animate__fadeIn}

Panel data (also called longitudinal data) has observations on multiple entities, each observed at multiple time periods. Let's create a simulated dataset to illustrate:

```{r panel-data-generation, message=FALSE, warning=FALSE}
# Set seed for reproducibility
set.seed(123)

# Create simulated panel data with clearer patterns
n_entities <- 30  # Number of entities (e.g., counties)
n_years <- 8      # Number of time periods (2015-2022)

# Generate entity-specific fixed effects with more variation
entities <- data.frame(
  id = 1:n_entities,
  # Create entity effects that are strongly correlated with x_mean
  entity_effect = rnorm(n_entities, mean = 0, sd = 3),  # Larger SD for clearer visualization
  
  # Create entity-specific mean levels of x with meaningful names
  education_level = runif(n_entities, min = 10, max = 40),  # College education rate (%)
  poverty_rate = runif(n_entities, min = 5, max = 30),      # Poverty rate (%)
  
  # Add a time-invariant characteristic
  urbanicity = sample(c("Urban", "Suburban", "Rural"), n_entities, replace = TRUE, 
                     prob = c(0.3, 0.4, 0.3))
)

# Induce correlation between entity effect and education level (important for demonstrating bias)
entities$entity_effect <- 0.7 * scale(entities$education_level) + 0.3 * entities$entity_effect

# Create panel data
panel_data <- expand.grid(id = 1:n_entities, year = 2015:2022)

# Merge entity effects
panel_data <- merge(panel_data, entities, by = "id")

# Generate variables with clearer time trends and policy changes
panel_data <- panel_data %>%
  group_by(id) %>%
  mutate(
    # Create time-varying education level with both trend and noise
    education = education_level + (year - 2015) * 0.5 + rnorm(n_years, mean = 0, sd = 1),
    
    # Create time-varying poverty with yearly fluctuations
    poverty = poverty_rate + sin((year - 2015) * pi/4) * 2 + rnorm(n_years, mean = 0, sd = 1),
    
    # Add a policy intervention in 2019
    policy_change = ifelse(year >= 2019, 1, 0),
    
    # Add a time effect with a clear break in 2019 (e.g., COVID impact)
    time_effect = 0.4 * (year - 2015) + ifelse(year >= 2020, 3, 0),
    
    # Generate mortality rate outcome with meaningful coefficients
    mortality_rate = 
      20 +                     # Base level
      entity_effect +          # Entity fixed effect
      -0.5 * education +       # Education effect (each % point reduces mortality by 0.5)
      0.3 * poverty +          # Poverty effect (each % point increases mortality by 0.3)
      -2 * policy_change +     # Policy effect (reduces mortality by 2)
      time_effect +            # Time trend and structural break
      rnorm(n_years, mean = 0, sd = 1.5)  # Random noise
  ) %>%
  ungroup()

# Convert factor variables
panel_data$urbanicity <- factor(panel_data$urbanicity, levels = c("Urban", "Suburban", "Rural"))

# Show a sample of the data
datatable(head(panel_data, 10), 
          options = list(pageLength = 5, 
                         scrollX = TRUE),
          caption = "Sample of Simulated County Health Data") %>%
  formatRound(columns = c('education', 'poverty', 'mortality_rate'), digits = 1)

# Simple summary statistics
summary_stats <- panel_data %>%
  group_by(year) %>%
  summarize(
    avg_mortality = mean(mortality_rate),
    avg_education = mean(education),
    avg_poverty = mean(poverty),
    policy_adoption = mean(policy_change) * 100,
    .groups = 'drop'
  )

# Display summary statistics by year
kable(summary_stats, caption = "Average Values by Year") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(5:8, background = "#e8f4f8")  # Highlight post-policy years
```

In this simulated dataset:
- Each county (ID) has observations across 8 years (2015-2022)
- `education` is the percentage of residents with college education
- `poverty` is the poverty rate
- `mortality_rate` is our outcome variable (deaths per 100,000 population)
- `policy_change` indicates implementation of a health policy starting in 2019
- `entity_effect` represents unobserved characteristics of each county (normally, we wouldn't observe this variable!)

Let's visualize this panel data to better understand its structure:

```{r panel-viz, fig.height=7}
# Visualize the panel data for first 10 entities
panel_data %>%
  filter(id <= 10) %>%
  ggplot(aes(x = year, y = mortality_rate, color = factor(id), group = id)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3) +
  geom_vline(xintercept = 2019, linetype = "dashed", color = "gray50") +
  annotate("text", x = 2019.2, y = max(panel_data$mortality_rate[panel_data$id <= 10]), 
           label = "Policy Change", hjust = 0, vjust = 1, color = "gray50") +
  labs(title = "Mortality Rates Across Time by County",
       x = "Year",
       y = "Mortality Rate (per 100,000)",
       color = "County ID") +
  theme_minimal() +
  theme(legend.position = "right")
```

Notice how each county has its own trajectory over time! This is what makes panel data so rich - we can observe both variation across counties and variation over time. You can also see a general reduction in mortality rates after the policy implementation in 2019.

## The Entity Fixed Effect Problem {.animate__animated .animate__fadeIn}

To understand why fixed effects and random effects models are necessary, let's visualize the relationship between education levels and mortality rates:

```{r pooled-ols-viz}
# Plot the relationship between education and mortality_rate
panel_data %>%
  ggplot(aes(x = education, y = mortality_rate, color = factor(id))) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") +
  geom_smooth(aes(group = id), method = "lm", se = FALSE, linewidth = 0.7) +
  labs(title = "Relationship Between Education and Mortality Rate",
       subtitle = "Black dashed line: pooled OLS, Colored lines: county-specific relationships",
       x = "College Education Rate (%)",
       y = "Mortality Rate (per 100,000)") +
  theme_minimal() +
  theme(legend.position = "none")
```

What's happening here?

- The **black dashed line** shows what happens if we ignore the panel structure and estimate a single relationship for all observations.
- The **colored lines** show the county-specific relationships.

We can see that each county appears to have its own "baseline" level of mortality. This is the **county fixed effect** or **unobserved heterogeneity** at work!

When we fail to account for these county-specific effects, our estimates of the relationship between education and mortality can be biased. This is where fixed effects and random effects models come in.

## Fixed Effects Models {.animate__animated .animate__fadeIn}

### Conceptual Understanding

**What Are Fixed Effects Models?**

Fixed effects models control for unobserved heterogeneity by estimating entity-specific intercepts. This approach effectively removes all time-invariant characteristics from the analysis, allowing us to focus on the within-entity variation.

The fixed effects model can be written as:

$$Y_{it} = \beta_0 + \beta_1 X_{it} + \alpha_i + \epsilon_{it}$$

Where:
- $Y_{it}$ is the outcome for entity $i$ at time $t$
- $X_{it}$ is the explanatory variable
- $\alpha_i$ is the entity-specific fixed effect
- $\epsilon_{it}$ is the error term

### Entity Fixed Effects Visualization

Let's visualize how fixed effects work by "de-meaning" our data (one way to implement fixed effects):

```{r fixed-effects-viz, fig.height=8}
# Calculate entity means with different column names to avoid conflicts
entity_means <- panel_data %>%
  group_by(id) %>%
  summarize(
    entity_mortality_mean = mean(mortality_rate),
    entity_education_mean = mean(education)
  )

# Add means to the original data with distinct column names
panel_data_demeaned <- panel_data %>%
  left_join(entity_means, by = "id") %>%
  mutate(
    mortality_demeaned = mortality_rate - entity_mortality_mean,
    education_demeaned = education - entity_education_mean
  )

# Create a two-panel plot
p3a <- panel_data %>%
  filter(id <= 10) %>%
  ggplot(aes(x = education, y = mortality_rate, color = factor(id))) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, linewidth = 0.7) +
  labs(title = "Before Fixed Effects",
       subtitle = "Original data with county-specific intercepts",
       x = "Education Rate (%)",
       y = "Mortality Rate (per 100,000)") +
  theme_minimal() +
  theme(legend.position = "none")

p3b <- panel_data_demeaned %>%
  filter(id <= 10) %>%
  ggplot(aes(x = education_demeaned, y = mortality_demeaned, color = factor(id))) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, linewidth = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 1) +
  labs(title = "After Fixed Effects",
       subtitle = "Demeaned data: county-specific means removed",
       x = "Education Rate (Demeaned)",
       y = "Mortality Rate (Demeaned)") +
  theme_minimal() +
  theme(legend.position = "none")

# Arrange plots vertically
p3a / p3b
```

**Key Insight:**

Notice how after demeaning (removing the county-specific means), the relationship between education and mortality becomes much more consistent across counties! The fixed effects transformation has removed the county-specific baselines, allowing us to focus on how changes in education relate to changes in mortality *within* each county.

### Fixed Effects in R

Let's estimate a fixed effects model using the `plm` package:

```{r fixed-effects-model}
# Estimate fixed effects model with multiple predictors
fe_model <- plm(mortality_rate ~ education + poverty + policy_change, 
                data = panel_data, index = c("id", "year"), model = "within")

# Display model results
fe_summary <- summary(fe_model)
fe_summary
```

The estimated coefficients tell us:
- A one percentage point increase in education rate is associated with a decrease of approximately 0.5 in mortality rate *within* counties
- A one percentage point increase in poverty rate is associated with an increase of approximately 0.3 in mortality rate *within* counties
- Implementation of the policy is associated with a decrease of approximately 2 in mortality rate *within* counties

## Random Effects Models {.animate__animated .animate__fadeIn}

### Conceptual Understanding

**What Are Random Effects Models?**

Random effects models also account for entity-specific effects, but they treat these effects as random variables drawn from a distribution, rather than as fixed parameters to be estimated.

The random effects model can be written as:

$$Y_{it} = \beta_0 + \beta_1 X_{it} + \alpha_i + \epsilon_{it}$$

Where $\alpha_i \sim N(0, \sigma_{\alpha}^2)$ is the entity-specific random effect.

### Random Effects Visualization

Let's visualize the random effects concept by showing how entity effects are modeled as draws from a distribution:

```{r random-effects-viz}
# Create a dataset of entity effects
entity_effects <- panel_data %>%
  distinct(id, entity_effect)

# Create a histogram of entity effects
ggplot(entity_effects, aes(x = entity_effect)) +
  geom_histogram(bins = 10, fill = "#4a90e2", color = "white", alpha = 0.7) +
  geom_density(color = "#e74c3c", linewidth = 1.5) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  labs(title = "Distribution of County-Specific Effects",
       subtitle = "Random effects model treats these as draws from a distribution",
       x = "County Effect on Mortality",
       y = "Count") +
  theme_minimal()
```

**Key Insight:**

The random effects approach models the county-specific effects as random draws from a distribution (shown by the red density curve). Rather than estimating each county's effect separately, we estimate the variance of this distribution.

### Random Effects in R

Let's estimate a random effects model:

```{r random-effects-model}
# Estimate random effects model with multiple predictors
re_model <- plm(mortality_rate ~ education + poverty + policy_change, 
                data = panel_data, index = c("id", "year"), model = "random")

# Display model results
re_summary <- summary(re_model)
re_summary
```

The random effects model gives us estimates that represent a weighted average of the within-county and between-county effects.

## Comparing Fixed and Random Effects {.animate__animated .animate__fadeIn}

Let's compare the approaches by adding a time-invariant predictor (urbanicity) that can only be estimated in the random effects model:

```{r re-with-time-invariant}
# Random effects model including urbanicity
re_model_full <- plm(mortality_rate ~ education + poverty + policy_change + urbanicity, 
                     data = panel_data, index = c("id", "year"), model = "random")

# Display results
summary(re_model_full)
```

Now let's compare all our models:

```{r model-comparison}
# Create a table comparing the models
model_comparison <- data.frame(
  Variable = c("Education", "Poverty", "Policy Change", "Urbanicity (Suburban)", "Urbanicity (Rural)"),
  Pooled_OLS = c(
    coef(lm(mortality_rate ~ education + poverty + policy_change + urbanicity, data = panel_data))[2],
    coef(lm(mortality_rate ~ education + poverty + policy_change + urbanicity, data = panel_data))[3],
    coef(lm(mortality_rate ~ education + poverty + policy_change + urbanicity, data = panel_data))[4],
    coef(lm(mortality_rate ~ education + poverty + policy_change + urbanicity, data = panel_data))[5],
    coef(lm(mortality_rate ~ education + poverty + policy_change + urbanicity, data = panel_data))[6]
  ),
  Fixed_Effects = c(
    coef(fe_model)[1],
    coef(fe_model)[2],
    coef(fe_model)[3],
    NA,
    NA
  ),
  Random_Effects = c(
    coef(re_model_full)[2],
    coef(re_model_full)[3],
    coef(re_model_full)[4],
    coef(re_model_full)[5],
    coef(re_model_full)[6]
  )
)

# Display as a formatted table
kable(model_comparison, 
      caption = "Comparison of Model Coefficients",
      digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
```

### Hausman Test

How do we decide between fixed and random effects? One common approach is the Hausman test:

```{r hausman-test}
hausman_test <- phtest(fe_model, re_model)
hausman_test
```

**Hausman Test Result:**

The p-value for the Hausman test indicates whether fixed effects or random effects are more appropriate for this data. In this case, a small p-value (less than 0.05) suggests that the fixed effects model is more appropriate, as the random effects assumption of no correlation between entity effects and regressors may be violated.

## When to Use Fixed vs. Random Effects {.animate__animated .animate__fadeIn}

The choice between fixed and random effects depends on several factors:

**Use Fixed Effects When:**
- You're primarily interested in the effects of variables that vary over time
- You suspect that unobserved entity characteristics are correlated with your explanatory variables
- The Hausman test indicates fixed effects is more appropriate
- You have a large number of entities relative to time periods
- You want to control for all time-invariant confounders

**Use Random Effects When:**
- You want to estimate effects of time-invariant variables
- You have reason to believe that entity effects are uncorrelated with explanatory variables
- You have a large number of entities with relatively few observations each
- You want more efficient estimation (smaller standard errors)
- Your entities can be viewed as a random sample from a larger population

## Interactive Demonstration: Effects of Parameter Changes {.animate__animated .animate__fadeIn}

To better understand these models, let's explore how changing key parameters affects our estimates. In this visualization, we'll see how increasing the correlation between entity effects and education impacts the bias in our estimates:

```{r parameter-simulation}
# Function to generate data with controlled correlation between entity effects and education
generate_panel_data <- function(corr_entity_educ, n_entities = 30, n_years = 8) {
  # Generate correlated entity effects and education means
  sigma <- matrix(c(1, corr_entity_educ, corr_entity_educ, 1), 2, 2)
  correlated_vars <- MASS::mvrnorm(n_entities, mu = c(0, 25), Sigma = sigma)
  
  entities <- data.frame(
    id = 1:n_entities,
    entity_effect = correlated_vars[, 1] * 3,  # Scale to have SD=3
    education_mean = correlated_vars[, 2]
  )
  
  # Create panel data
  panel_data <- expand.grid(id = 1:n_entities, year = 2015:(2015+n_years-1))
  
  # Merge entity effects
  panel_data <- merge(panel_data, entities, by = "id")
  
  # Generate variables
  panel_data <- panel_data %>%
    group_by(id) %>%
    mutate(
      # Education with time trend and noise
      education = education_mean + 0.5 * (year - 2015) + rnorm(n_years, mean = 0, sd = 1),
      
      # Policy change in 2019
      policy_change = ifelse(year >= 2019, 1, 0),
      
      # Generate mortality rate with true coefficients
      mortality_rate = 
        25 +                # Base level
        entity_effect +     # Entity fixed effect
        -0.5 * education +  # True education effect is -0.5
        -2 * policy_change + # Policy effect is -2
        rnorm(n_years, mean = 0, sd = 1)  # Random noise
    ) %>%
    ungroup()
  
  return(panel_data)
}

# Generate results for different correlation values
correlation_values <- seq(0, 0.9, by = 0.1)
simulation_results <- data.frame()

set.seed(456)
for(corr in correlation_values) {
  sim_data <- generate_panel_data(corr)
  
  # Estimate pooled OLS
  pooled_model <- lm(mortality_rate ~ education + policy_change, data = sim_data)
  
  # Estimate fixed effects model
  fe_model <- plm(mortality_rate ~ education + policy_change, 
                  data = sim_data, index = c("id", "year"), model = "within")
  
  # Estimate random effects model
  re_model <- plm(mortality_rate ~ education + policy_change, 
                  data = sim_data, index = c("id", "year"), model = "random")
  
  # Store results
  result_row <- data.frame(
    Correlation = corr,
    Pooled_OLS = coef(pooled_model)[2],
    Fixed_Effects = coef(fe_model)[1],
    Random_Effects = coef(re_model)[2],
    True_Effect = -0.5
  )
  
  simulation_results <- rbind(simulation_results, result_row)
}

# Reshape data for plotting
sim_results_long <- simulation_results %>%
  pivot_longer(
    cols = c(Pooled_OLS, Fixed_Effects, Random_Effects, True_Effect),
    names_to = "Model",
    values_to = "Coefficient"
  )

# Plot the results
ggplot(sim_results_long, aes(x = Correlation, y = Coefficient, color = Model, group = Model)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Fixed_Effects" = "#3498db", 
                               "Random_Effects" = "#2ecc71", 
                               "Pooled_OLS" = "#e74c3c",
                               "True_Effect" = "#000000")) +
  labs(title = "Impact of Entity Effect-Education Correlation on Model Estimates",
       subtitle = "True education effect = -0.5",
       x = "Correlation between County Effects and Education",
       y = "Estimated Education Coefficient",
       color = "Model") +
  theme_minimal() +
  geom_hline(yintercept = -0.5, linetype = "dashed", color = "gray40")
```

**Key Insight:**

When county effects are correlated with education (moving rightward on the x-axis), the pooled OLS and random effects estimates become increasingly biased. The fixed effects estimator remains unbiased regardless of this correlation, which is one of its key advantages!

## Time Fixed Effects {.animate__animated .animate__fadeIn}

So far, we've focused on entity fixed effects, but we can also include time fixed effects to account for period-specific shocks that affect all counties:

```{r time-fixed-effects}
# Estimate model with both entity and time fixed effects
twoways_model <- plm(mortality_rate ~ education + poverty + policy_change, 
                     data = panel_data, 
                     index = c("id", "year"), 
                     effect = "twoways",  # Both entity and time fixed effects
                     model = "within")

# Display model results
twoways_summary <- summary(twoways_model)
twoways_summary
```

Let's visualize the time effects in our data:

```{r time-effects-viz}
# Calculate average mortality by year
year_effects <- panel_data %>%
  group_by(year) %>%
  summarize(
    avg_mortality = mean(mortality_rate),
    avg_education = mean(education),
    avg_poverty = mean(poverty),
    policy_rate = mean(policy_change) * 100
  )

# Plot the time effects
ggplot(year_effects, aes(x = year, y = avg_mortality)) +
  geom_line(linewidth = 1.2, color = "#3498db") +
  geom_point(size = 4, color = "#3498db") +
  geom_vline(xintercept = 2019, linetype = "dashed", color = "gray50") +
  geom_vline(xintercept = 2020, linetype = "dashed", color = "gray50") +
  annotate("text", x = 2019.1, y = max(year_effects$avg_mortality), 
           label = "Policy Change", hjust = 0, vjust = 1, color = "gray50") +
  annotate("text", x = 2020.1, y = max(year_effects$avg_mortality) - 1, 
           label = "COVID Effect", hjust = 0, vjust = 1, color = "gray50") +
  labs(title = "Average Mortality Rate Over Time",
       subtitle = "These time patterns are captured by time fixed effects",
       x = "Year",
       y = "Average Mortality Rate (per 100,000)") +
  theme_minimal()
```

## Practical Applications in Sociology and Health Research {.animate__animated .animate__fadeIn}

Fixed effects and random effects models are extensively used in sociological and health research:

**Example: Health Disparities Research**

When studying county-level health disparities, researchers might use fixed effects models to control for unobserved county characteristics when examining how changes in policy affect health outcomes. This would control for relatively stable factors like geographic location, historical settlement patterns, or long-standing cultural factors.

My research on the Black-White mental health paradox uses county fixed effects to control for unmeasured county characteristics while examining how neighborhood disadvantage affects mental health outcomes for different racial groups.

**Example: Educational Outcomes**

When studying how school resources affect student performance, researchers might use random effects if they have a sample of schools drawn from a larger population and want to make inferences about all schools, not just those in the sample.

## Conclusion {.animate__animated .animate__fadeIn}

Fixed effects and random effects models offer powerful approaches to analyzing panel data, each with distinct advantages:

**Fixed Effects**
- **Strengths:** Controls for all time-invariant confounders, robust to correlation between entity effects and explanatory variables
- **Limitations:** Cannot estimate coefficients for time-invariant variables, less efficient if entity effects are truly random

**Random Effects**
- **Strengths:** More efficient estimation, can include time-invariant variables, useful for making population inferences
- **Limitations:** Biased if entity effects are correlated with explanatory variables, requires more assumptions

The choice between fixed and random effects should be guided by your research question, the nature of your data, and statistical tests like the Hausman test. In practice, many researchers report both models for completeness and to check robustness.

## References {.animate__animated .animate__fadeIn}

- Allison, P. D. (2009). *Fixed effects regression models*. SAGE Publications.
- Wooldridge, J. M. (2010). *Econometric analysis of cross section and panel data*. MIT Press.
- Bell, A., & Jones, K. (2015). Explaining fixed effects: Random effects modeling of time-series cross-sectional and panel data. *Political Science Research and Methods*, 3(1), 133-153.
- Croissant, Y., & Millo, G. (2008). Panel data econometrics in R: The plm package. *Journal of Statistical Software*, 27(2), 1-43.